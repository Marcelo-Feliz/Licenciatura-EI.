||||||||A entropia é uma medida da incerteza associada a uma variável aleatória.||||||||||  A entropia mede-se em bits, Hartleys ou nats, consoante a base do logaritmo usada é 2, 10 ou , respectivamente.||||||||||A informação mutua NAO mede a incerteza conjunta de duas variáveis aleatórias|||||||||Distribuição estacionaria de uma cadeira de Markov- P(A) = ((1-B)/((1-B)+(1-A))||||||||||O programa crashar num certo dia é independente do que acontece ao programa nos outros dias.|||||||||||Se num certo dia a probabilidade do servidor estar online for p, após notarmos que o programa não reportou o estado do servidor, podemos actualizar a probabilidade do servidor estar online para ((0.1p)/(1-0.9p)||||||||||O output do programa é uma variável binária "online", "ausência de mensagem".|||||||||0 <= H(X) <= log2|X||||||||||| 0 <= I(X;Y) <= min(H(X),H(Y))||||||||||||||||||P[1 0 0 1] tem infinitas distribuições estacionarias P[0 1 1 0] nao tem distribuição estacionaria P[0.5 0.5 0.5 0.5] tem uma distribuição estacionaria||||||||||Diz-se que uma cadeira de MArkov é aperiódica se: Nenhum estado tem periodo maior que 1||||||||||||Indique as propriedades que uma cadeia de Markov deve satisfazer para garantir a convergência para uma única distribuição de probabilidade estacionária.: Ser aperiódica.  Ser irredutível.||||||||||Diz-se que uma cadeia de Markov é irredutível se:É possível transitar entre quaisquer pares de estados, em tempo finito, com probabilidade não nula.|||||||||||Uma distribuição estacionária U satisfaz necessariamente a equação Pu = u onde P é a matriz de transição da cadeia de Markov.|||||Em geral, uma cadeia de Markov pode ter zero, uma ou uma infinidade de distribuições estacionárias.||||||||||Diz-se que um estado de uma cadeia de Markov é periódico com perído N se:Só pode ser visitado em instantes de tempo múltiplos de N.||||||||||cadeia de Markov é irredutível - É possível transitar entre quaisquer pares de estados, em tempo finito, com probabilidade não nula.

|||||Um código é não-singular se cada símbolo tem uma palavra de código diferente, isto é, se não há palavras de código repetidas.|||||||||O codigo é instantaneo se for o melhor||||||||O problema de compressão de dados pode ser formulado como um problema de optimização. Qual é a formulação correcta? Minimizar ExP(x)l(x) com restrição Ex2-l(x)<=1(correspone a desigualdade de Kraft)|||||||||||||| Desigualdade de Kraft: A desigualdade de Kraft permite saber se é possível construir um código instantâneo cujas palavras de código têm certos comprimentos dados.| Existe um código instantâneo em que as palavras de código têm comprimentos 2, 3, 1, 3.||||||||||||||Inque quais os passos que fazem parte do algoritmo do código de Shannon. Calcular as probabilidades acumuladas F(x) = Ei<xP(i). Calcular o comprimento de cada palavra de código l(x) = [-log2p(x)]. Obter palavra de código a partir dos primeiros l(x) bits a seguir ao ponto decimal da expansão binária de F(x) .Ordenar as probabilidades por ordem decrescente.|||||||||||O comprimento médio de um código de Shannon satisfaz:H(x)<=L(c)<H(x)+1|||||||||  A ineficiência do código de Shannon é a diferença L(c)-H(x) entre o comprimento médio efectivo do código e a entropia da fonte: ExP(x)log2p(x)/q(x) onde p(x) é a distribuição de r'probabilidade real dos símbolos do alfabeto e q(x)=2-l(x).||||||||Tendo em consideração o algoritmo de compressão Shannon-Fano-Elias: As palavras de código são obtidas da parte à direita da vírgula da função de probabilidade acumulada modificada| As palavras de código têm comprimentosl(x)=[-log2p(x)]+1.||||||||||Tendo em consideração o algoritmo de codificação aritmética, assinale quais as afirmações verdadeiras.|O algoritmo consiste em determinar uma única palavra de código que corresponde à mensagem completa.| A compressão obtida é geralmente superior à do código de Huffman.||||||||||||||

|||Codigo de Shannon é com x | p(x) | F(x) F(x)bin | l(x) | C(x)(Ordenar por ordem decrescente)||||||||Fano|dividir em dois grupos perto de 50%(ordenar por ordem decrescente)||||||||Codigo de Huffmam(fazer arvore) ligar os que tem menos probabilidades e dar 0 e 1 aos 2.|||||||||||Codigo de Huffman adaptativo|0 esquerda,1direita. espaço esquerda, numero direita||||||||||||Fano-Elias| o comprimento tem mais 1 de comprimento|||F(x)dec = 1/2 + os anteriores|||||||[-log2P(x)]+1|||||||H(x)+1 <=L(C)<H(x)+2|||||||||Codificação aritmetica|fazer arvore,ir para proxima se nao houver mais opçoes na linha, multiplicar a ultima P por 1/2(e depois tranformar em binario). A compressao vai ser [-logPpalavra]+1 de comprimento.O algoritmo consiste em determinar uma única palavra de código que corresponde à mensagem completa.|||||||||LZ78|input:ABBCBCABA|Output:(0,A) (0,B) (2,C) (3,A) (2,A)||||||||LZW|dict[posicao] = "atual" + 1ºsimbolo de "proximo"(ABAAABABAB)dá:0, 1, 0, 4, 3, 6|||||||||Matriz[0.8 0.2][0.2 0.8] Canal binário simetrico(2 entradas e 2 saidas significa simetrico)||||[(0.9 0)(0.1 0.1)(0 0.9)] Canal com perdas(erasure channel)||||||||A cardinalidade do alfabeto: Entrada é os da linha de cima, saida é os da ultima coluna||||||||||Capacidade do canal[3.2]: C = maxP(x)I(X;Y)||||||||x prob na coord(0.1) capacidade canal[2.2] = 1-(-0.3log0.3-(1-0.3)log(1-0.3))||||||||Codigo de Hamming: (1-Pe)^7+7(1-Pe)^6xPe||||||||||Familias:(31,26)(15,11)|||||||| Quantos bits de dados: 2m-1-m|||||||No total quantos bits: 2m-1||||||

|||||Num sistema electrónico, uma porta lógica AND correcta? P=([1 0.5][0 0.5])|No OR a resposta é [(0.5 0)(0.5 1)]|No XOR a resposta é [(0.75 0.25)(0.25 0.75)]|||||||PiA x 1-PiB + 1-PiA x PiB|||||||Quais das seguintes propriedades caracterizam um canal discreto sem memória?: Os alfabetos de entrada e saída são conjuntos discretos.|A saída do canal só depende (probabilisticamente) da entrada presente e não das entradas e saídas passadas.|||||||||| A concatenação de canais apenas pode ser efectuada quando o alfabeto de saída de cada canal é igual ao alfabeto de entrada do canal seguinte. A concatenação de N canais binários, não necessariamente simétricos, mas todos idênticos, é equivalente a um único canal binário com matriz de transição Peq = Pn . A concatenação de N canais com matrizes de transição , compatíveis, onde é o canal de entrada e é o canal de saída, tem um canal equivalente com matriz de transição dada pelo produto matricial Peq = PN...P2P1.|||||||||canal discreto sem memória - Função de probabilidade condicionada da saída dada a entrada,P(y|x).Os alfabetos de entrada e saída são conjuntos discretos|A saída do canal só depende da entrada actual e não das entradas e saídas passadas.|||||||||propriedades da capacidade de canal: A capacidade satisfaz a desigualdade C<=log|Y|.| A capacidade satisfaz a desigualdade C<=log|X|.| Mede-se em bits, Hartleys ou nats consoante a base do logaritmo usada é 2, 10 ou a base natural, respectivamente.| A capacidade é um número não negativo.||||||||Propriedades do codigo de hamming: As palavras de código têm comprimento 7 e transportam 4 bits de dados.| A distância de Hamming mínima entre palavras de código é 3.|O código de Hamming permite detectar erros caso sejam corrompidos 1 ou 2 bits.|||||||